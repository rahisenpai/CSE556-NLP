{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BERT Tokenizer & SQuADv2 and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "from typing import Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import QuestionAnsweringModelOutput\n",
    "from collections import defaultdict\n",
    "\n",
    "torch.manual_seed(seed=42)\n",
    "wandb.login()\n",
    "\n",
    "dataset = load_dataset('rajpurkar/squad_v2')\n",
    "dataset['train'] = dataset['train'].shuffle(seed=42).select(range(48000)) #select 48k samples for finetuning\n",
    "tokenizer = BertTokenizerFast.from_pretrained('spanbert/spanbert-large-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(examples):\n",
    "    questions = [q.strip() for q in examples['question']] #remove leading and trailing whitespaces\n",
    "    inputs = tokenizer(questions, examples['context'], max_length=512,\n",
    "                truncation='only_second', stride=128, return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True, padding='max_length')\n",
    "\n",
    "    offset_mapping = inputs.pop('offset_mapping') #mapping between tokens and original text positions\n",
    "    sample_map = inputs.pop('overflow_to_sample_mapping') #mapping of tokenized examples with original examples\n",
    "\n",
    "    #map answers to the tokenized context\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i] #index in dataset\n",
    "        answer = examples['answers'][sample_idx] #true answer for the question (ground truth)\n",
    "        start_char = answer['answer_start'][0] if answer['answer_start'] else 0\n",
    "        end_char = start_char + len(answer['text'][0]) if answer['text'] else 0\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        #find the start and end of the context\n",
    "        idx = 0\n",
    "        while idx < len(sequence_ids) and sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while idx < len(sequence_ids) and sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        #if the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "\n",
    "        #else find the token indices that correspond to the start and end of the answer\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs['start_positions'] = torch.tensor(start_positions)\n",
    "    inputs['end_positions'] = torch.tensor(end_positions)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def exact_match_score(predictions, references):\n",
    "    assert len(predictions) == len(references), \"Lists must have the same length\"\n",
    "    matches = sum(p == r for p, r in zip(predictions, references))\n",
    "    return matches / len(references) * 100 # Convert to percentage\n",
    "\n",
    "\n",
    "def compute_em(preds):\n",
    "    label = preds.label_ids\n",
    "    pred = np.argmax(preds.predictions, axis=-1)\n",
    "    predictions, references = [], []\n",
    "    for i in range(len(label[0])):\n",
    "        predictions.append(str(pred[0][i]) + ',' + str(pred[1][i]))\n",
    "        references.append(str(label[0][i]) + ',' + str(label[1][i]))\n",
    "    return exact_match_score(predictions, references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_dataset, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning spanbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanbert = BertForQuestionAnswering.from_pretrained('SpanBERT/spanbert-large-cased')\n",
    "\n",
    "wandb.init(entity='cv-himanshu', project='finetuning-spanberts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./results', eval_strategy='epoch',\n",
    "                learning_rate=1e-5, num_train_epochs=6, weight_decay=0.01,\n",
    "                per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "                report_to='wandb', logging_dir='./logs', logging_steps=50,\n",
    "                label_names=['start_positions', 'end_positions'],)\n",
    "\n",
    "trainer = Trainer(model=spanbert, args=training_args, processing_class=tokenizer,\n",
    "    train_dataset=tokenized_dataset['train'], eval_dataset=tokenized_dataset['validation'])\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(tokenized_dataset['validation'])\n",
    "\n",
    "spanbert_em = compute_em(preds)\n",
    "print(spanbert_em)\n",
    "print(f\"SpanBERT Exact Match Score: {spanbert_em:.2f} %\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning SpanBERT_CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanBERTCRF(BertForQuestionAnswering):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Additional hidden layers\n",
    "        self.fc1 = nn.Linear(config.hidden_size, config.hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(config.hidden_size // 2, config.hidden_size // 4)\n",
    "        \n",
    "        self.start_classifier = nn.Linear(config.hidden_size // 4, self.num_labels)\n",
    "        self.end_classifier = nn.Linear(config.hidden_size // 4, self.num_labels)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        self.start_crf = CRF(num_tags=config.num_labels, batch_first=True)  # CRF for start positions\n",
    "        self.end_crf = CRF(num_tags=config.num_labels, batch_first=True)  # CRF for end positions\n",
    "\n",
    "    def forward( self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        start_positions: Optional[torch.Tensor] = None,\n",
    "        end_positions: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], QuestionAnsweringModelOutput]:\n",
    "        r\"\"\"\n",
    "        start_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n",
    "            Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence\n",
    "            are not taken into account for computing the loss.\n",
    "        end_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n",
    "            Positions are clamped to the length of the sequence (`sequence_length`). Position outside of the sequence\n",
    "            are not taken into account for computing the loss.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert( input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "        hidden = self.fc1(sequence_output)\n",
    "        hidden = self.relu(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = self.fc2(hidden)\n",
    "        hidden = self.relu(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "\n",
    "        start_logits = self.start_classifier(hidden)  # (batch_size, seq_length, num_labels)\n",
    "        end_logits = self.end_classifier(hidden)  # (batch_size, seq_length, num_labels)\n",
    "\n",
    "        total_loss = None\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions = start_positions.clamp(0, ignored_index)\n",
    "            end_positions = end_positions.clamp(0, ignored_index)\n",
    "\n",
    "            batch_size, seq_length = start_logits.shape[:2]\n",
    "\n",
    "            # Create label tensors for CRF\n",
    "            start_labels = torch.zeros((batch_size, seq_length), dtype=torch.long, device=input_ids.device)\n",
    "            end_labels = torch.zeros((batch_size, seq_length), dtype=torch.long, device=input_ids.device)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                start, end = start_positions[i].item(), end_positions[i].item()\n",
    "                if 0 <= start < seq_length:\n",
    "                    start_labels[i, start] = 1 # Mark the correct start position\n",
    "                if 0 <= end < seq_length:\n",
    "                    end_labels[i, end] = 1 # Mark the correct end position\n",
    "\n",
    "            # Compute CRF loss separately for start and end logits\n",
    "            start_loss = -self.start_crf(start_logits, start_labels, mask=attention_mask.bool(), reduction=\"mean\")\n",
    "            end_loss = -self.end_crf(end_logits, end_labels, mask=attention_mask.bool(), reduction=\"mean\")\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "\n",
    "        start_predictions = self.start_crf.decode(start_logits, mask=attention_mask.bool())\n",
    "        end_predictions = self.end_crf.decode(end_logits, mask=attention_mask.bool())\n",
    "\n",
    "        bs, sq = start_logits.shape[:2]\n",
    "        start_preds = torch.zeros((bs, sq), device=input_ids.device)\n",
    "        end_preds = torch.zeros((bs, sq), device=input_ids.device)\n",
    "\n",
    "        for i, (ss, es) in enumerate(zip(start_predictions, end_predictions)):\n",
    "            temp = ss.index(1) if 1 in ss else 0\n",
    "            start_preds[i, temp] = 1\n",
    "            temp = es.index(1) if 1 in es else 0\n",
    "            end_preds[i, temp] = 1\n",
    "\n",
    "        return (total_loss, start_preds, end_preds) if total_loss is not None else (start_preds, end_preds)\n",
    "\n",
    "\n",
    "def preprocess_evalset(examples):\n",
    "    inputs = tokenizer(examples['question'], examples['context'], max_length=512,\n",
    "                truncation='only_second', stride=128, return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True, padding='max_length')\n",
    "\n",
    "    sample_map = inputs.pop('overflow_to_sample_mapping', list(range((len(inputs['input_ids'])))))\n",
    "    inputs['example_id'] = [examples['id'][i] for i in sample_map]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def post_process_to_compute_em(features, preds):\n",
    "    start_logits, end_logits = preds.predictions\n",
    "    label = preds.label_ids\n",
    "    predictions = {}\n",
    "    references = {}\n",
    "    example_to_features = defaultdict(list)\n",
    "    for i, feature in enumerate(features):\n",
    "        example_to_features[feature['example_id']].append((i, feature))\n",
    "        references[feature['example_id']] = str(label[0][i]) + ',' + str(label[1][i])\n",
    "\n",
    "    for example_id, feature_list in example_to_features.items():\n",
    "        best_score = -float(\"inf\")\n",
    "        best_answer = \"\"\n",
    "        for idx, features in feature_list:\n",
    "            offset = features['offset_mapping']\n",
    "            start_logit = start_logits[idx]\n",
    "            end_logit = end_logits[idx]\n",
    "            for start_index in range((len(start_logit))):\n",
    "                for end_index in range(start_index, len(end_logit)):\n",
    "                    if offset[start_index] == (0, 0) or offset[end_index] == (0, 0):\n",
    "                        continue\n",
    "                    score = start_logit[start_index] + end_logit[end_index]\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_answer = f'{start_index},{end_index}'\n",
    "        predictions[example_id] = best_answer\n",
    "    return predictions, references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanbert_crf = SpanBERTCRF.from_pretrained('SpanBERT/spanbert-large-cased')\n",
    "\n",
    "wandb.init(entity='cv-himanshu', project='finetuning-spanberts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args_crf = TrainingArguments(output_dir='./results', eval_strategy='epoch',\n",
    "                learning_rate=1e-5, num_train_epochs=6, weight_decay=0.01,\n",
    "                per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "                report_to='wandb', logging_dir='./logs', logging_steps=50,\n",
    "                label_names=['start_positions', 'end_positions'],)\n",
    "\n",
    "trainer_crf = Trainer(model=spanbert_crf, args=training_args_crf, processing_class=tokenizer, \n",
    "    train_dataset=tokenized_dataset['train'], eval_dataset=tokenized_dataset['validation'])\n",
    "\n",
    "trainer_crf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_val_set = dataset['validation'].map(preprocess_evalset, batched=True, remove_columns=dataset[\"validation\"].column_names)\n",
    "\n",
    "preds = trainer_crf.predict(tokenized_dataset['validation'])\n",
    "\n",
    "hopefully_final_predictions, references = post_process_to_compute_em(final_val_set, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanbert_crf_em = exact_match_score(predictions=[hopefully_final_predictions[id] for id in references],\n",
    "                                    references=[references[id] for id in references])\n",
    "print(spanbert_em)\n",
    "print(f\"SpanBERT Exact Match Score: {spanbert_em:.2f} %\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer & SQuADv2 and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhimanshu22216\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries and modules\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "from typing import Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import QuestionAnsweringModelOutput\n",
    "from collections import defaultdict\n",
    "\n",
    "#set seed for reproducibility and wandb login\n",
    "torch.manual_seed(seed=42)\n",
    "wandb.login()\n",
    "\n",
    "#load the dataset and tokenizer\n",
    "dataset = load_dataset('rajpurkar/squad_v2')\n",
    "dataset['train'] = dataset['train'].shuffle(seed=42).select(range(60000)) #select 60k samples for finetuning\n",
    "tokenizer = BertTokenizerFast.from_pretrained('spanbert/spanbert-large-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(examples):\n",
    "    \"\"\"\n",
    "    This function preprocesses the dataset by tokenizing the context and question,\n",
    "    and finding the start and end positions of the answer in the context.\n",
    "    The code below is heavily inspired by the Hugging Face NLP course for Question Answering.\n",
    "    link to the course: https://huggingface.co/learn/nlp-course/en/chapter7/7\n",
    "    \"\"\"\n",
    "    questions = [q.strip() for q in examples['question']] #remove leading and trailing whitespaces\n",
    "    inputs = tokenizer(questions, examples['context'], max_length=512,\n",
    "                truncation='only_second', stride=128, return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True, padding='max_length')\n",
    "\n",
    "    offset_mapping = inputs.pop('offset_mapping') #mapping between tokens and original text positions\n",
    "    sample_map = inputs.pop('overflow_to_sample_mapping') #mapping of tokenized examples with original examples\n",
    "\n",
    "    #map answers to the tokenized context\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i] #index in dataset\n",
    "        answer = examples['answers'][sample_idx] #true answer for the question (ground truth)\n",
    "        start_char = answer['answer_start'][0] if answer['answer_start'] else 0\n",
    "        end_char = start_char + len(answer['text'][0]) if answer['text'] else 0\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        #find the start and end of the context\n",
    "        idx = 0\n",
    "        while idx < len(sequence_ids) and sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while idx < len(sequence_ids) and sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        #if the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "\n",
    "        #else find the token indices that correspond to the start and end of the answer\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs['start_positions'] = torch.tensor(start_positions)\n",
    "    inputs['end_positions'] = torch.tensor(end_positions)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def exact_match_score(predictions, references):\n",
    "    assert len(predictions) == len(references), \"Lists must have the same length\"\n",
    "    matches = sum(p == r for p, r in zip(predictions, references))\n",
    "    return matches / len(references) * 100 # Convert to percentage\n",
    "\n",
    "\n",
    "def compute_em(preds):\n",
    "    \"\"\"\n",
    "    This function is used to post-process the predictions and compute the exact match score for SpanBERT model.\n",
    "    This function converts the start and end positions of the answer to a string\n",
    "    (instead of transforming to actual text from the context) and then computes the exact match score.\n",
    "    This should work as good as the variation where we convert the token indices to text\n",
    "    because its just a string comparison so either they are same or not.\n",
    "    \"\"\"\n",
    "    label = preds.label_ids #actual start and end positions of the answer\n",
    "    pred = np.argmax(preds.predictions, axis=-1) #predicted start and end positions of the answer\n",
    "    predictions, references = [], []\n",
    "    for i in range(len(label[0])):\n",
    "        predictions.append(str(pred[0][i]) + ',' + str(pred[1][i]))\n",
    "        references.append(str(label[0][i]) + ',' + str(label[1][i]))\n",
    "    return exact_match_score(predictions, references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 60217\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 11985\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess the dataset\n",
    "tokenized_dataset = dataset.map(preprocess_dataset, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning spanbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gpu1/himanshu/workspace/wandb/run-20250317_064027-h5fxba2j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/h5fxba2j' target=\"_blank\">fine-wildflower-81</a></strong> to <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts' target=\"_blank\">https://wandb.ai/cv-himanshu/finetuning-spanberts</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/h5fxba2j' target=\"_blank\">https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/h5fxba2j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/h5fxba2j?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe4acd81d30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model and initialize wandb run\n",
    "spanbert = BertForQuestionAnswering.from_pretrained('SpanBERT/spanbert-large-cased')\n",
    "\n",
    "wandb.init(entity='cv-himanshu', project='finetuning-spanberts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 1:43:15, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.428000</td>\n",
       "      <td>1.221892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.000800</td>\n",
       "      <td>0.946458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.799900</td>\n",
       "      <td>0.879596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.672100</td>\n",
       "      <td>0.894592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.562800</td>\n",
       "      <td>0.910687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.534800</td>\n",
       "      <td>0.928524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2826, training_loss=0.993496185486315, metrics={'train_runtime': 6198.6139, 'train_samples_per_second': 58.288, 'train_steps_per_second': 0.456, 'total_flos': 3.3554369366983066e+17, 'train_loss': 0.993496185486315, 'epoch': 6.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define training arguments and train with Trainer API\n",
    "training_args = TrainingArguments(output_dir='./results', eval_strategy='epoch',\n",
    "                learning_rate=1e-5, num_train_epochs=6, weight_decay=0.01,\n",
    "                per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "                report_to='wandb', logging_dir='./logs', logging_steps=50,\n",
    "                label_names=['start_positions', 'end_positions'],)\n",
    "\n",
    "trainer = Trainer(model=spanbert, args=training_args, processing_class=tokenizer,\n",
    "    train_dataset=tokenized_dataset['train'], eval_dataset=tokenized_dataset['validation'])\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.27951606174385\n",
      "SpanBERT Exact Match Score: 70.28 %\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▁▁▂▂</td></tr><tr><td>eval/runtime</td><td>▁▃▁███</td></tr><tr><td>eval/samples_per_second</td><td>█▆█▁▁▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇█▂▁▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▄█▄▇▇▂▃▄▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.92852</td></tr><tr><td>eval/runtime</td><td>70.7082</td></tr><tr><td>eval/samples_per_second</td><td>169.499</td></tr><tr><td>eval/steps_per_second</td><td>1.329</td></tr><tr><td>test/loss</td><td>0.92852</td></tr><tr><td>test/runtime</td><td>70.8578</td></tr><tr><td>test/samples_per_second</td><td>169.142</td></tr><tr><td>test/steps_per_second</td><td>1.327</td></tr><tr><td>total_flos</td><td>3.3554369366983066e+17</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>2826</td></tr><tr><td>train/grad_norm</td><td>7.84855</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5348</td></tr><tr><td>train_loss</td><td>0.9935</td></tr><tr><td>train_runtime</td><td>6198.6139</td></tr><tr><td>train_samples_per_second</td><td>58.288</td></tr><tr><td>train_steps_per_second</td><td>0.456</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-wildflower-81</strong> at: <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/h5fxba2j' target=\"_blank\">https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/h5fxba2j</a><br> View project at: <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts' target=\"_blank\">https://wandb.ai/cv-himanshu/finetuning-spanberts</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250317_064027-h5fxba2j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict on validation set and compute the exact match score\n",
    "preds = trainer.predict(tokenized_dataset['validation'])\n",
    "\n",
    "spanbert_em = compute_em(preds)\n",
    "print(spanbert_em)\n",
    "print(f\"SpanBERT Exact Match Score: {spanbert_em:.2f} %\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning SpanBERT_CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanBERTCRF(BertForQuestionAnswering):\n",
    "    \"\"\"\n",
    "    This is a custom model class that extends the SpanBERT model and adds a CRF layer on top of it.\n",
    "    The CRF layer is used to predict the start and end positions of the answer in the context.\n",
    "    It also has some additional hidden layers to learn better representations.\n",
    "    This code is heavily inspired by the BertForQuestionAnswering class in the Hugging Face Transformers library.\n",
    "    link to the code: https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initialize the model with SpanBERT and additional hidden layers.\n",
    "        \"\"\"\n",
    "        super().__init__(config)\n",
    "        # Additional hidden layers\n",
    "        self.fc1 = nn.Linear(config.hidden_size, config.hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(config.hidden_size // 2, config.hidden_size // 4)\n",
    "        \n",
    "        self.start_classifier = nn.Linear(config.hidden_size // 4, self.num_labels)\n",
    "        self.end_classifier = nn.Linear(config.hidden_size // 4, self.num_labels)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        self.start_crf = CRF(num_tags=config.num_labels, batch_first=True)  # CRF for start positions\n",
    "        self.end_crf = CRF(num_tags=config.num_labels, batch_first=True)  # CRF for end positions\n",
    "\n",
    "    def forward( self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        start_positions: Optional[torch.Tensor] = None,\n",
    "        end_positions: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], QuestionAnsweringModelOutput]:\n",
    "        \"\"\"\n",
    "        Defines the forward pass for the model.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        #get the outputs from SpanBERT model\n",
    "        outputs = self.bert( input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        #get the output of last hidden layer from SpanBERT\n",
    "        sequence_output = outputs[0]  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "        #pass the output through additional hidden layers\n",
    "        hidden = self.fc1(sequence_output)\n",
    "        hidden = self.relu(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = self.fc2(hidden)\n",
    "        hidden = self.relu(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "\n",
    "        #get the logits for start and end positions\n",
    "        start_logits = self.start_classifier(hidden)  # (batch_size, seq_length, num_labels)\n",
    "        end_logits = self.end_classifier(hidden)  # (batch_size, seq_length, num_labels)\n",
    "\n",
    "        total_loss = None\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            # If we are on multi-GPU, split add a dimension\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions = start_positions.clamp(0, ignored_index)\n",
    "            end_positions = end_positions.clamp(0, ignored_index)\n",
    "\n",
    "            batch_size, seq_length = start_logits.shape[:2]\n",
    "\n",
    "            # Create label tensors for CRF\n",
    "            start_labels = torch.zeros((batch_size, seq_length), dtype=torch.long, device=input_ids.device)\n",
    "            end_labels = torch.zeros((batch_size, seq_length), dtype=torch.long, device=input_ids.device)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                start, end = start_positions[i].item(), end_positions[i].item()\n",
    "                if 0 <= start < seq_length:\n",
    "                    start_labels[i, start] = 1 # Mark the correct start position\n",
    "                if 0 <= end < seq_length:\n",
    "                    end_labels[i, end] = 1 # Mark the correct end position\n",
    "\n",
    "            # Compute CRF loss separately for start and end logits\n",
    "            start_loss = -self.start_crf(start_logits, start_labels, mask=attention_mask.bool(), reduction=\"mean\")\n",
    "            end_loss = -self.end_crf(end_logits, end_labels, mask=attention_mask.bool(), reduction=\"mean\")\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "\n",
    "        #perform crf decoding to get the start and end positions\n",
    "        start_predictions = self.start_crf.decode(start_logits, mask=attention_mask.bool())\n",
    "        end_predictions = self.end_crf.decode(end_logits, mask=attention_mask.bool())\n",
    "\n",
    "        #convert the predictions to one-hot encoded tensors\n",
    "        bs, sq = start_logits.shape[:2]\n",
    "        start_preds = torch.zeros((bs, sq), device=input_ids.device)\n",
    "        end_preds = torch.zeros((bs, sq), device=input_ids.device)\n",
    "\n",
    "        for i, (ss, es) in enumerate(zip(start_predictions, end_predictions)):\n",
    "            temp = ss.index(1) if 1 in ss else 0\n",
    "            start_preds[i, temp] = 1\n",
    "            temp = es.index(1) if 1 in es else 0\n",
    "            end_preds[i, temp] = 1\n",
    "\n",
    "        #return the total loss and start and end predictions\n",
    "        return (total_loss, start_preds, end_preds) if total_loss is not None else (start_preds, end_preds)\n",
    "\n",
    "\n",
    "def preprocess_evalset(examples):\n",
    "    \"\"\"\n",
    "    This function is used to preprocess the evaluation dataset by tokenizing the context and question.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(examples['question'], examples['context'], max_length=512,\n",
    "                truncation='only_second', stride=128, return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True, padding='max_length')\n",
    "\n",
    "    sample_map = inputs.pop('overflow_to_sample_mapping', list(range((len(inputs['input_ids'])))))\n",
    "    inputs['example_id'] = [examples['id'][i] for i in sample_map]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def post_process_to_compute_em(features, preds):\n",
    "    \"\"\"\n",
    "    This function is used to post-process the predictions and compute the exact match score for SpanBERTCRF model.\n",
    "    \"\"\"\n",
    "    start_logits, end_logits = preds.predictions #predicted start and end positions of the answer\n",
    "    label = preds.label_ids #actual start and end positions of the answer\n",
    "    predictions = {}\n",
    "    references = {}\n",
    "    id_array = []\n",
    "    example_to_features = defaultdict(list)\n",
    "    #mapping the features to the example ids, also storing the references\n",
    "    for i, feature in enumerate(features):\n",
    "        example_to_features[feature['example_id']].append((i, feature))\n",
    "        references[feature['example_id']] = str(label[0][i]) + ',' + str(label[1][i])\n",
    "        id_array.append(feature['example_id'])\n",
    "\n",
    "    #iterate over the examples and find the best start and end positions\n",
    "    for example_id, feature_list in example_to_features.items():\n",
    "        best_score = -float(\"inf\")\n",
    "        best_answer = \"\"\n",
    "        #iterate over the features and find the best start and end positions\n",
    "        for idx, features in feature_list:\n",
    "            offset = features['offset_mapping']\n",
    "            start_logit = start_logits[idx]\n",
    "            end_logit = end_logits[idx]\n",
    "            #iterate over the start and end positions and find the best answer\n",
    "            for start_index in range((len(start_logit))):\n",
    "                for end_index in range(start_index, len(end_logit)):\n",
    "                    if offset[start_index] == (0, 0) or offset[end_index] == (0, 0):\n",
    "                        #unanswerable question so skip\n",
    "                        continue\n",
    "                    #compute the score for the answer\n",
    "                    score = start_logit[start_index] + end_logit[end_index]\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_answer = f'{start_index},{end_index}'\n",
    "        predictions[example_id] = best_answer\n",
    "\n",
    "    #create reference and prediction lists using the dictionaries\n",
    "    final_preds, final_refs = [], []\n",
    "    for id in id_array:\n",
    "        final_preds.append(predictions[id])\n",
    "        final_refs.append(references[id])\n",
    "    return exact_match_score(final_preds, final_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SpanBERTCRF were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['end_classifier.bias', 'end_classifier.weight', 'end_crf.end_transitions', 'end_crf.start_transitions', 'end_crf.transitions', 'fc1.bias', 'fc1.weight', 'fc2.bias', 'fc2.weight', 'qa_outputs.bias', 'qa_outputs.weight', 'start_classifier.bias', 'start_classifier.weight', 'start_crf.end_transitions', 'start_crf.start_transitions', 'start_crf.transitions']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gpu1/himanshu/workspace/wandb/run-20250317_040055-8tzco75n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/8tzco75n' target=\"_blank\">absurd-moon-80</a></strong> to <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts' target=\"_blank\">https://wandb.ai/cv-himanshu/finetuning-spanberts</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/8tzco75n' target=\"_blank\">https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/8tzco75n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/8tzco75n?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f39616c63c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess the evaluation set, load the model and initialize wandb run\n",
    "final_val_set = dataset['validation'].map(preprocess_evalset, batched=True, remove_columns=dataset[\"validation\"].column_names)\n",
    "final_val_set\n",
    "\n",
    "spanbert_crf = SpanBERTCRF.from_pretrained('SpanBERT/spanbert-large-cased')\n",
    "\n",
    "wandb.init(entity='cv-himanshu', project='finetuning-spanberts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2826' max='2826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2826/2826 2:28:57, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.376100</td>\n",
       "      <td>6.269810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.614000</td>\n",
       "      <td>2.195243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.857000</td>\n",
       "      <td>1.657076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.401600</td>\n",
       "      <td>1.471706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.233700</td>\n",
       "      <td>1.386216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.153600</td>\n",
       "      <td>1.426081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/gpu1/anaconda3/envs/newenv/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2826, training_loss=8.340884785743276, metrics={'train_runtime': 8941.6355, 'train_samples_per_second': 40.407, 'train_steps_per_second': 0.316, 'total_flos': 3.362731018478346e+17, 'train_loss': 8.340884785743276, 'epoch': 6.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define training arguments and train with Trainer API\n",
    "training_args_crf = TrainingArguments(output_dir='./results', eval_strategy='epoch',\n",
    "                learning_rate=1e-5, num_train_epochs=6, weight_decay=0.01,\n",
    "                per_device_train_batch_size=64, per_device_eval_batch_size=64,\n",
    "                report_to='wandb', logging_dir='./logs', logging_steps=50,\n",
    "                label_names=['start_positions', 'end_positions'],)\n",
    "\n",
    "trainer_crf = Trainer(model=spanbert_crf, args=training_args_crf, processing_class=tokenizer, \n",
    "    train_dataset=tokenized_dataset['train'], eval_dataset=tokenized_dataset['validation'])\n",
    "\n",
    "trainer_crf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.03254067584481\n",
      "SpanBERT-CRF Exact Match Score: 66.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▂▃▆█</td></tr><tr><td>eval/samples_per_second</td><td>██▇▆▃▁</td></tr><tr><td>eval/steps_per_second</td><td>███▆▃▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▇██▆▄▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.42608</td></tr><tr><td>eval/runtime</td><td>128.6654</td></tr><tr><td>eval/samples_per_second</td><td>93.149</td></tr><tr><td>eval/steps_per_second</td><td>0.731</td></tr><tr><td>test/loss</td><td>1.42608</td></tr><tr><td>test/runtime</td><td>128.0138</td></tr><tr><td>test/samples_per_second</td><td>93.623</td></tr><tr><td>test/steps_per_second</td><td>0.734</td></tr><tr><td>total_flos</td><td>3.362731018478346e+17</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>2826</td></tr><tr><td>train/grad_norm</td><td>14.6693</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1536</td></tr><tr><td>train_loss</td><td>8.34088</td></tr><tr><td>train_runtime</td><td>8941.6355</td></tr><tr><td>train_samples_per_second</td><td>40.407</td></tr><tr><td>train_steps_per_second</td><td>0.316</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">absurd-moon-80</strong> at: <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/8tzco75n' target=\"_blank\">https://wandb.ai/cv-himanshu/finetuning-spanberts/runs/8tzco75n</a><br> View project at: <a href='https://wandb.ai/cv-himanshu/finetuning-spanberts' target=\"_blank\">https://wandb.ai/cv-himanshu/finetuning-spanberts</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250317_040055-8tzco75n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict on validation set and compute the exact match score\n",
    "preds = trainer_crf.predict(tokenized_dataset['validation'])\n",
    "\n",
    "spanbert_crf_em = post_process_to_compute_em(final_val_set, preds)\n",
    "print(spanbert_crf_em)\n",
    "print(f\"SpanBERT-CRF Exact Match Score: {spanbert_crf_em:.2f} %\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

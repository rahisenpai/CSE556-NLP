{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import gensim.downloader as api\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Importing conlleval for evaluation\n",
    "from conlleval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    processed_data = []\n",
    "    \n",
    "    for item in data:\n",
    "        sentence = item['sentence']\n",
    "        aspect_terms = item['aspect_terms']\n",
    "        \n",
    "        # Use NLTK's tokenizer for better accuracy\n",
    "        tokens = word_tokenize(sentence)\n",
    "        \n",
    "        # Initialize all labels as 'O'\n",
    "        labels = ['O'] * len(tokens)\n",
    "        \n",
    "        # Extract aspect terms\n",
    "        terms = []\n",
    "        \n",
    "        for aspect in aspect_terms:\n",
    "            term = aspect['term']\n",
    "            terms.append(term)\n",
    "            \n",
    "            # Get the start and end positions\n",
    "            start = int(aspect['from'])\n",
    "            end = int(aspect['to'])\n",
    "            \n",
    "            # Find the tokens that correspond to this aspect term\n",
    "            term_indices = []\n",
    "            char_index = 0\n",
    "            for i, token in enumerate(tokens):\n",
    "                token_start = char_index\n",
    "                token_end = token_start + len(token)\n",
    "                \n",
    "                # Check if this token overlaps with the aspect term\n",
    "                if token_end > start and token_start < end:\n",
    "                    term_indices.append(i)\n",
    "                \n",
    "                char_index = token_end + 1  # +1 for the space\n",
    "            \n",
    "            # Apply BIO tagging\n",
    "            if term_indices:\n",
    "                labels[term_indices[0]] = 'B'  # Beginning of aspect term\n",
    "                for idx in term_indices[1:]:\n",
    "                    labels[idx] = 'I'  # Inside of aspect term\n",
    "        \n",
    "        processed_item = {\n",
    "            'sentence': sentence,\n",
    "            'tokens': tokens,\n",
    "            'labels': labels,\n",
    "            'aspect_terms': terms\n",
    "        }\n",
    "        \n",
    "        processed_data.append(processed_item)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(processed_data, f, indent=2)\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AspectTermDataset(Dataset):\n",
    "    def __init__(self, data, embedding_model, label_to_idx):\n",
    "        self.data = data\n",
    "        self.embedding_model = embedding_model\n",
    "        self.embedding_dim = embedding_model.vector_size\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.unk_vector = np.zeros(self.embedding_dim)  # Zero vector for unknown words\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        tokens = item['tokens']\n",
    "        labels = item['labels']\n",
    "        \n",
    "        # Get word embeddings directly from the model\n",
    "        token_embeddings = []\n",
    "        for token in tokens:\n",
    "            token_lower = token.lower()\n",
    "            if token_lower in self.embedding_model:\n",
    "                token_embeddings.append(self.embedding_model[token_lower])\n",
    "            else:\n",
    "                token_embeddings.append(self.unk_vector)\n",
    "        \n",
    "        token_embeddings = np.array(token_embeddings)\n",
    "        label_indices = [self.label_to_idx[label] for label in labels]\n",
    "        \n",
    "        return {\n",
    "            'embeddings': torch.tensor(token_embeddings, dtype=torch.float),\n",
    "            'labels': torch.tensor(label_indices, dtype=torch.long),\n",
    "            'lengths': len(tokens)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function for batching\n",
    "def collate_fn(batch):\n",
    "    # Sort the batch by length in descending order\n",
    "    batch = sorted(batch, key=lambda x: x['lengths'], reverse=True)\n",
    "    \n",
    "    # Get the length of each sequence\n",
    "    lengths = [item['lengths'] for item in batch]\n",
    "    \n",
    "    # Get the maximum length in the batch\n",
    "    max_length = max(lengths)\n",
    "    embedding_dim = batch[0]['embeddings'].shape[1]\n",
    "    \n",
    "    # Pad the sequences\n",
    "    embeddings = torch.zeros(len(batch), max_length, embedding_dim, dtype=torch.float)\n",
    "    labels = torch.zeros(len(batch), max_length, dtype=torch.long)\n",
    "    \n",
    "    for i, item in enumerate(batch):\n",
    "        embeddings[i, :item['lengths']] = item['embeddings']\n",
    "        labels[i, :item['lengths']] = item['labels']\n",
    "    \n",
    "    return {\n",
    "        'embeddings': embeddings,\n",
    "        'labels': labels,\n",
    "        'lengths': torch.tensor(lengths, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified RNN Model (non-bidirectional)\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # No embedding layer as we're using embeddings directly\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, embeddings, lengths):\n",
    "        # Pack the sequences\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        packed_output, hidden = self.rnn(packed_embedded)\n",
    "        \n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        logits = self.fc(output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Modified GRU Model (non-bidirectional)\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        \n",
    "        # No embedding layer as we're using embeddings directly\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, embeddings, lengths):\n",
    "        # Pack the sequences\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        packed_output, hidden = self.gru(packed_embedded)\n",
    "        \n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        logits = self.fc(output)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load GloVe embeddings\n",
    "# def load_glove_embeddings(path, word_to_idx, embedding_dim=300):\n",
    "#     embeddings = np.zeros((len(word_to_idx), embedding_dim))\n",
    "    \n",
    "#     with open(path, 'r', encoding='utf-8') as f:\n",
    "#         for line in f:\n",
    "#             values = line.split()\n",
    "#             word = values[0]\n",
    "#             if word in word_to_idx:\n",
    "#                 vector = np.asarray(values[1:], dtype='float32')\n",
    "#                 embeddings[word_to_idx[word]] = vector\n",
    "    \n",
    "#     return torch.FloatTensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load FastText embeddings\n",
    "# def load_fasttext_embeddings(path, word_to_idx, embedding_dim=300):\n",
    "#     model = KeyedVectors.load_word2vec_format(path, binary=False)\n",
    "#     embeddings = np.zeros((len(word_to_idx), embedding_dim))\n",
    "    \n",
    "#     for word, idx in word_to_idx.items():\n",
    "#         if word in model:\n",
    "#             embeddings[idx] = model[word]\n",
    "    \n",
    "#     return torch.FloatTensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            embeddings = batch['embeddings'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            lengths = batch['lengths']\n",
    "            \n",
    "            outputs = model(embeddings, lengths)\n",
    "            \n",
    "            # Reshape outputs and labels for loss calculation\n",
    "            outputs_flat = outputs.view(-1, outputs.shape[-1])\n",
    "            labels_flat = labels.view(-1)\n",
    "            \n",
    "            # Calculate loss (ignore padding)\n",
    "            mask = labels_flat != 0  # Assuming 0 is the padding index\n",
    "            loss = criterion(outputs_flat[mask], labels_flat[mask])\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "            \n",
    "            # Collect predictions and labels (ignoring padding)\n",
    "            for i in range(len(lengths)):\n",
    "                length = lengths[i].item()\n",
    "                pred = predictions[i, :length].cpu().numpy()\n",
    "                lab = labels[i, :length].cpu().numpy()\n",
    "                \n",
    "                all_predictions.extend(pred)\n",
    "                all_labels.extend(lab)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    return total_loss / len(data_loader), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, device, epochs, model_save_path):\n",
    "    best_f1 = 0.0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            embeddings = batch['embeddings'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            lengths = batch['lengths']\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(embeddings, lengths)\n",
    "            \n",
    "            # Reshape outputs and labels for loss calculation\n",
    "            outputs = outputs.view(-1, outputs.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            \n",
    "            # Calculate loss (ignore padding)\n",
    "            mask = labels != 0  # Assuming 0 is the padding index\n",
    "            loss = criterion(outputs[mask], labels[mask])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_f1 = evaluate_model(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f'Model saved to {model_save_path}')\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to BIO format\n",
    "def convert_to_bio(idx_to_label, predictions, lengths):\n",
    "    bio_predictions = []\n",
    "    \n",
    "    for i, length in enumerate(lengths):\n",
    "        # Convert tensor values to Python integers before dictionary lookup\n",
    "        bio_predictions.append([idx_to_label[pred.item()] for pred in predictions[i, :length]])\n",
    "    \n",
    "    return bio_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_conlleval(tokens, true_labels, pred_labels):\n",
    "    results = []\n",
    "    \n",
    "    for sample_tokens, sample_true, sample_pred in zip(tokens, true_labels, pred_labels):\n",
    "        for token, true, pred in zip(sample_tokens, sample_true, sample_pred):\n",
    "            results.append(f\"{token} {true} {pred}\")\n",
    "        results.append(\"\")  # Empty line between sentences\n",
    "    \n",
    "    # Remove debug print\n",
    "    eval_output = evaluate(results)\n",
    "    \n",
    "    # Extract chunk-level metrics\n",
    "    chunk_metrics = eval_output['overall']['chunks']['evals']\n",
    "    # Extract tag-level metrics\n",
    "    tag_metrics = eval_output['overall']['tags']['evals']\n",
    "    \n",
    "    return chunk_metrics, tag_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses, title, save_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data, embedding_model, label_to_idx, idx_to_label, device):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_tokens = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    embedding_dim = embedding_model.vector_size\n",
    "    unk_vector = np.zeros(embedding_dim)  # Zero vector for unknown words\n",
    "    \n",
    "    # Process each item separately to maintain direct mapping to test_data\n",
    "    for item in test_data:\n",
    "        tokens = item['tokens']\n",
    "        labels = item['labels']\n",
    "        \n",
    "        # Get word embeddings directly\n",
    "        token_embeddings = []\n",
    "        for token in tokens:\n",
    "            token_lower = token.lower()\n",
    "            if token_lower in embedding_model:\n",
    "                token_embeddings.append(embedding_model[token_lower])\n",
    "            else:\n",
    "                token_embeddings.append(unk_vector)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        token_embeddings = np.array(token_embeddings)\n",
    "        token_tensor = torch.tensor([token_embeddings], dtype=torch.float).to(device)\n",
    "        length = torch.tensor([len(tokens)], dtype=torch.long)\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = model(token_tensor, length)\n",
    "        _, predictions = torch.max(outputs, dim=2)\n",
    "        \n",
    "        # Convert predictions to BIO format\n",
    "        label_indices = [label_to_idx[label] for label in labels]\n",
    "        bio_predictions = [idx_to_label[pred.item()] for pred in predictions[0, :len(tokens)]]\n",
    "        bio_true = labels  # Already in BIO format\n",
    "        \n",
    "        all_predictions.append(bio_predictions)\n",
    "        all_tokens.append(tokens)\n",
    "        all_true_labels.append(bio_true)\n",
    "    \n",
    "    # Calculate both chunk-level and tag-level metrics using conlleval\n",
    "    chunk_metrics, tag_metrics = calculate_f1_conlleval(all_tokens, all_true_labels, all_predictions)\n",
    "    \n",
    "    print(\"Chunk-level evaluation:\")\n",
    "    print(f\"  Precision: {chunk_metrics['prec']:.4f}\")\n",
    "    print(f\"  Recall:    {chunk_metrics['rec']:.4f}\")\n",
    "    print(f\"  F1 Score:  {chunk_metrics['f1']:.4f}\")\n",
    "    \n",
    "    print(\"\\nTag-level evaluation:\")\n",
    "    print(f\"  Precision: {tag_metrics['prec']:.4f}\")\n",
    "    print(f\"  Recall:    {tag_metrics['rec']:.4f}\")\n",
    "    print(f\"  F1 Score:  {tag_metrics['f1']:.4f}\")\n",
    "    \n",
    "    return chunk_metrics, tag_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    \n",
    "    # Preprocess data\n",
    "    print('Preprocessing data...')\n",
    "    train_data = preprocess_data('train.json', 'train_task_1.json')\n",
    "    val_data = preprocess_data('val.json', 'val_task_1.json')\n",
    "    \n",
    "    # Define label mapping\n",
    "    label_to_idx = {'<PAD>': 0, 'O': 1, 'B': 2, 'I': 3}\n",
    "    idx_to_label = {0: '<PAD>', 1: 'O', 2: 'B', 3: 'I'}\n",
    "    \n",
    "    # Save label mapping\n",
    "    with open(\"label_mapping.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"label_to_idx\": label_to_idx,\n",
    "            \"idx_to_label\": idx_to_label\n",
    "        }, f)\n",
    "    \n",
    "    # Load pretrained embeddings    \n",
    "    try:\n",
    "        print('Loading pretrained embeddings...')\n",
    "        \n",
    "        # Load models\n",
    "        print('Loading models...')\n",
    "        glove_model = api.load(\"glove-wiki-gigaword-300\")\n",
    "        print('GloVe model loaded')\n",
    "        fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "        print('FastText model loaded')\n",
    "        \n",
    "        embedding_dim = 300\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading from gensim: {e}\")\n",
    "        print(\"Exiting as we need pre-trained embeddings.\")\n",
    "        return\n",
    "    \n",
    "    # Get the embedding dimension\n",
    "    embedding_dim = glove_model.vector_size\n",
    "    hidden_dim = 256\n",
    "    output_dim = len(label_to_idx)\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    print('Creating datasets and dataloaders...')\n",
    "    train_dataset_glove = AspectTermDataset(train_data, glove_model, label_to_idx)\n",
    "    val_dataset_glove = AspectTermDataset(val_data, glove_model, label_to_idx)\n",
    "    train_dataset_fasttext = AspectTermDataset(train_data, fasttext_model, label_to_idx)\n",
    "    val_dataset_fasttext = AspectTermDataset(val_data, fasttext_model, label_to_idx)\n",
    "    \n",
    "    batch_size = 32\n",
    "    train_loader_glove = DataLoader(train_dataset_glove, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader_glove = DataLoader(val_dataset_glove, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    train_loader_fasttext = DataLoader(train_dataset_fasttext, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader_fasttext = DataLoader(val_dataset_fasttext, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    # Create the directory for saving models if it doesn't exist\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    \n",
    "    # Define models\n",
    "    models = {\n",
    "        'RNN_GloVe': {\n",
    "            'model': RNNModel(embedding_dim, hidden_dim, output_dim).to(device),\n",
    "            'train_loader': train_loader_glove,\n",
    "            'val_loader': val_loader_glove,\n",
    "            'embedding_model': glove_model\n",
    "        },\n",
    "        'RNN_FastText': {\n",
    "            'model': RNNModel(embedding_dim, hidden_dim, output_dim).to(device),\n",
    "            'train_loader': train_loader_fasttext,\n",
    "            'val_loader': val_loader_fasttext,\n",
    "            'embedding_model': fasttext_model\n",
    "        },\n",
    "        'GRU_GloVe': {\n",
    "            'model': GRUModel(embedding_dim, hidden_dim, output_dim).to(device),\n",
    "            'train_loader': train_loader_glove,\n",
    "            'val_loader': val_loader_glove,\n",
    "            'embedding_model': glove_model\n",
    "        },\n",
    "        'GRU_FastText': {\n",
    "            'model': GRUModel(embedding_dim, hidden_dim, output_dim).to(device),\n",
    "            'train_loader': train_loader_fasttext,\n",
    "            'val_loader': val_loader_fasttext,\n",
    "            'embedding_model': fasttext_model\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding index\n",
    "    epochs = 30\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for name, model_config in models.items():\n",
    "        print(f'\\nTraining {name}...')\n",
    "        model = model_config['model']\n",
    "        train_loader = model_config['train_loader']\n",
    "        val_loader = model_config['val_loader']\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        model_save_path = f'models/{name}_best.pt'\n",
    "        \n",
    "        train_losses, val_losses = train(model, train_loader, val_loader, optimizer, criterion, device, epochs, model_save_path)\n",
    "        \n",
    "        # Plot losses\n",
    "        plot_losses(train_losses, val_losses, f'{name} Training and Validation Loss', f'plots/{name}_loss.png')\n",
    "        \n",
    "        # Load the best model\n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        chunk_metrics, tag_metrics = test_model(model, val_data, model_config['embedding_model'], label_to_idx, idx_to_label, device)\n",
    "        \n",
    "        results[name] = {\n",
    "            'chunk_f1': chunk_metrics['f1'],\n",
    "            'chunk_prec': chunk_metrics['prec'],\n",
    "            'chunk_rec': chunk_metrics['rec'],\n",
    "            'tag_f1': tag_metrics['f1'],\n",
    "            'tag_prec': tag_metrics['prec'],\n",
    "            'tag_rec': tag_metrics['rec']\n",
    "        }\n",
    "        \n",
    "        print(f'{name} validation results:')\n",
    "        print(f\"  Chunk-level -> Precision: {chunk_metrics['prec']:.4f}, Recall: {chunk_metrics['rec']:.4f}, F1: {chunk_metrics['f1']:.4f}\")\n",
    "        print(f\"  Tag-level   -> Precision: {tag_metrics['prec']:.4f}, Recall: {tag_metrics['rec']:.4f}, F1: {tag_metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Print results summary\n",
    "    print('\\nResults Summary:')\n",
    "    for name, result in results.items():\n",
    "        print(f\"{name}: Chunk F1 = {result['chunk_f1']:.4f}, Tag F1 = {result['tag_f1']:.4f}\")\n",
    "    \n",
    "    # Find the best model based on chunk-level F1\n",
    "    best_model_name = max(results, key=lambda x: results[x]['chunk_f1'])\n",
    "    print(f'\\nBest model: {best_model_name} with Chunk F1 = {results[best_model_name][\"chunk_f1\"]:.4f} and Tag F1 = {results[best_model_name][\"tag_f1\"]:.4f}')\n",
    "    \n",
    "    # Save best model info\n",
    "    with open('best_model_info.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'model_name': best_model_name,\n",
    "            'chunk_f1': results[best_model_name]['chunk_f1'],\n",
    "            'tag_f1': results[best_model_name]['tag_f1']\n",
    "        }, f)\n",
    "    \n",
    "    # Save embedding model information\n",
    "    with open('embedding_model_info.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'best_model': best_model_name,\n",
    "            'glove_model_name': \"glove-wiki-gigaword-300\",\n",
    "            'fasttext_model_name': \"fasttext-wiki-news-subwords-300\"\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_test(test_file, model_path, model_type, embedding_model_name):\n",
    "    # Load label mapping\n",
    "    with open(\"label_mapping.json\", \"r\") as f:\n",
    "        label_data = json.load(f)\n",
    "    label_to_idx = label_data[\"label_to_idx\"]\n",
    "    # Convert idx_to_label keys to integers\n",
    "    idx_to_label = {int(k): v for k, v in label_data[\"idx_to_label\"].items()}\n",
    "    \n",
    "    # Process the test file\n",
    "    test_data = preprocess_data(test_file, \"test_task_1.json\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load embedding model\n",
    "    try:\n",
    "        print(f'Loading {embedding_model_name} embeddings...')\n",
    "        embedding_model = api.load(embedding_model_name)\n",
    "        print(f'{embedding_model_name} loaded')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embedding model: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Get the embedding dimension\n",
    "    embedding_dim = embedding_dim = embedding_model.vector_size\n",
    "    hidden_dim = 256\n",
    "    output_dim = len(label_to_idx)\n",
    "    \n",
    "    # Initialize model\n",
    "    if model_type.startswith('RNN'):\n",
    "        model = RNNModel(embedding_dim, hidden_dim, output_dim).to(device)\n",
    "    elif model_type.startswith('GRU'):\n",
    "        model = GRUModel(embedding_dim, hidden_dim, output_dim).to(device)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Load model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    # Test the model\n",
    "    chunk_metrics, tag_metrics = test_model(model, test_data, embedding_model, label_to_idx, idx_to_label, device)\n",
    "    \n",
    "    print(\"Test Results:\")\n",
    "    print(\"Chunk-level:\")\n",
    "    print(f\"  Precision: {chunk_metrics['prec']:.4f}\")\n",
    "    print(f\"  Recall:    {chunk_metrics['rec']:.4f}\")\n",
    "    print(f\"  F1 Score:  {chunk_metrics['f1']:.4f}\")\n",
    "    print(\"Tag-level:\")\n",
    "    print(f\"  Precision: {tag_metrics['prec']:.4f}\")\n",
    "    print(f\"  Recall:    {tag_metrics['rec']:.4f}\")\n",
    "    print(f\"  F1 Score:  {tag_metrics['f1']:.4f}\")\n",
    "    \n",
    "    return chunk_metrics, tag_metrics\n",
    "\n",
    "def test_with_best_model(test_file):\n",
    "    # Load best model info\n",
    "    with open('best_model_info.json', 'r') as f:\n",
    "        best_model_info = json.load(f)\n",
    "    \n",
    "    # Load embedding model info\n",
    "    with open('embedding_model_info.json', 'r') as f:\n",
    "        embedding_info = json.load(f)\n",
    "    \n",
    "    best_model_name = best_model_info['model_name']\n",
    "    model_path = f'models/{best_model_name}_best.pt'\n",
    "    \n",
    "    # Determine which embedding model to use\n",
    "    if 'GloVe' in best_model_name:\n",
    "        embedding_model_name = embedding_info['glove_model_name']\n",
    "    else:\n",
    "        embedding_model_name = embedding_info['fasttext_model_name']\n",
    "    \n",
    "    # Extract model type (RNN or GRU)\n",
    "    model_type = best_model_name.split('_')[0]\n",
    "    \n",
    "    print(f\"Testing with best model: {best_model_name}\")\n",
    "    print(f\"Using embedding model: {embedding_model_name}\")\n",
    "    print(f\"Model type: {model_type}\")\n",
    "    \n",
    "    # Test the model\n",
    "    chunk_metrics, tag_metrics = load_and_test(test_file, model_path, model_type, embedding_model_name)\n",
    "    \n",
    "    return chunk_metrics, tag_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "Preprocessing data...\n",
      "Loading pretrained embeddings...\n",
      "Loading models...\n",
      "GloVe model loaded\n",
      "FastText model loaded\n",
      "Creating datasets and dataloaders...\n",
      "\n",
      "Training RNN_GloVe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 77/77 [00:01<00:00, 74.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.3361, Val Loss: 0.2208, Val F1: 0.9199\n",
      "Model saved to models/RNN_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 77/77 [00:00<00:00, 160.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.2348, Val Loss: 0.2142, Val F1: 0.9231\n",
      "Model saved to models/RNN_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 77/77 [00:00<00:00, 164.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.2259, Val Loss: 0.2239, Val F1: 0.9244\n",
      "Model saved to models/RNN_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 77/77 [00:00<00:00, 156.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.2112, Val Loss: 0.2002, Val F1: 0.9275\n",
      "Model saved to models/RNN_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 77/77 [00:00<00:00, 152.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.2037, Val Loss: 0.1977, Val F1: 0.9278\n",
      "Model saved to models/RNN_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 77/77 [00:00<00:00, 150.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.1958, Val Loss: 0.1909, Val F1: 0.9310\n",
      "Model saved to models/RNN_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 77/77 [00:00<00:00, 151.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.1936, Val Loss: 0.1933, Val F1: 0.9279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 77/77 [00:00<00:00, 153.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.1849, Val Loss: 0.1942, Val F1: 0.9265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 77/77 [00:00<00:00, 160.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.1751, Val Loss: 0.1819, Val F1: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 77/77 [00:00<00:00, 152.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.1682, Val Loss: 0.1828, Val F1: 0.9318\n",
      "Model saved to models/RNN_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 77/77 [00:00<00:00, 143.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.1652, Val Loss: 0.1800, Val F1: 0.9332\n",
      "Model saved to models/RNN_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 77/77 [00:00<00:00, 149.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.1565, Val Loss: 0.1878, Val F1: 0.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 77/77 [00:00<00:00, 153.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.1490, Val Loss: 0.1904, Val F1: 0.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 77/77 [00:00<00:00, 157.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.1376, Val Loss: 0.1854, Val F1: 0.9341\n",
      "Model saved to models/RNN_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 77/77 [00:00<00:00, 169.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.1278, Val Loss: 0.2069, Val F1: 0.9311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 77/77 [00:00<00:00, 164.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.1210, Val Loss: 0.2116, Val F1: 0.9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 77/77 [00:00<00:00, 165.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.1089, Val Loss: 0.2213, Val F1: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 77/77 [00:00<00:00, 172.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.0952, Val Loss: 0.2451, Val F1: 0.9189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 77/77 [00:00<00:00, 168.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.0885, Val Loss: 0.2456, Val F1: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 77/77 [00:00<00:00, 166.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.0840, Val Loss: 0.2439, Val F1: 0.9306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 77/77 [00:00<00:00, 160.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.0748, Val Loss: 0.2618, Val F1: 0.9263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 77/77 [00:00<00:00, 161.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.0655, Val Loss: 0.2675, Val F1: 0.9242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 77/77 [00:00<00:00, 160.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.0489, Val Loss: 0.2995, Val F1: 0.9210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 77/77 [00:00<00:00, 163.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.0614, Val Loss: 0.3052, Val F1: 0.9278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 77/77 [00:00<00:00, 151.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.0473, Val Loss: 0.3047, Val F1: 0.9271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 77/77 [00:00<00:00, 174.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.0463, Val Loss: 0.3231, Val F1: 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 77/77 [00:00<00:00, 165.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.0364, Val Loss: 0.3323, Val F1: 0.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 77/77 [00:00<00:00, 164.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.0309, Val Loss: 0.3422, Val F1: 0.9249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 77/77 [00:00<00:00, 168.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.0300, Val Loss: 0.3565, Val F1: 0.9251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 77/77 [00:00<00:00, 162.57it/s]\n",
      "/tmp/ipykernel_2655251/20128414.py:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  token_tensor = torch.tensor([token_embeddings], dtype=torch.float).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.0250, Val Loss: 0.3697, Val F1: 0.9250\n",
      "Chunk-level evaluation:\n",
      "  Precision: 0.6185\n",
      "  Recall:    0.5784\n",
      "  F1 Score:  0.5978\n",
      "\n",
      "Tag-level evaluation:\n",
      "  Precision: 0.9386\n",
      "  Recall:    0.9386\n",
      "  F1 Score:  0.9386\n",
      "RNN_GloVe validation results:\n",
      "  Chunk-level -> Precision: 0.6185, Recall: 0.5784, F1: 0.5978\n",
      "  Tag-level   -> Precision: 0.9386, Recall: 0.9386, F1: 0.9386\n",
      "\n",
      "Training RNN_FastText...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 77/77 [00:00<00:00, 163.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.4345, Val Loss: 0.2556, Val F1: 0.9082\n",
      "Model saved to models/RNN_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 77/77 [00:00<00:00, 167.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.2575, Val Loss: 0.2141, Val F1: 0.9195\n",
      "Model saved to models/RNN_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 77/77 [00:00<00:00, 159.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.2354, Val Loss: 0.2284, Val F1: 0.9230\n",
      "Model saved to models/RNN_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 77/77 [00:00<00:00, 148.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.2183, Val Loss: 0.1918, Val F1: 0.9313\n",
      "Model saved to models/RNN_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 77/77 [00:00<00:00, 149.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.2132, Val Loss: 0.1912, Val F1: 0.9327\n",
      "Model saved to models/RNN_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 77/77 [00:00<00:00, 158.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.2064, Val Loss: 0.1964, Val F1: 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 77/77 [00:00<00:00, 159.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.2024, Val Loss: 0.1985, Val F1: 0.9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 77/77 [00:00<00:00, 161.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.2004, Val Loss: 0.1853, Val F1: 0.9333\n",
      "Model saved to models/RNN_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 77/77 [00:00<00:00, 161.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.2035, Val Loss: 0.1925, Val F1: 0.9331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 77/77 [00:00<00:00, 156.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.1897, Val Loss: 0.1949, Val F1: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 77/77 [00:00<00:00, 159.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.1846, Val Loss: 0.1867, Val F1: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 77/77 [00:00<00:00, 164.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.1818, Val Loss: 0.1888, Val F1: 0.9335\n",
      "Model saved to models/RNN_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 77/77 [00:00<00:00, 165.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.1752, Val Loss: 0.1913, Val F1: 0.9307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 77/77 [00:00<00:00, 166.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.1747, Val Loss: 0.1944, Val F1: 0.9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 77/77 [00:00<00:00, 164.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.1727, Val Loss: 0.2150, Val F1: 0.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 77/77 [00:00<00:00, 164.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.1733, Val Loss: 0.1876, Val F1: 0.9345\n",
      "Model saved to models/RNN_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 77/77 [00:00<00:00, 165.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.1652, Val Loss: 0.1975, Val F1: 0.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 77/77 [00:00<00:00, 165.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.1603, Val Loss: 0.1984, Val F1: 0.9315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 77/77 [00:00<00:00, 164.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.1602, Val Loss: 0.2055, Val F1: 0.9283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 77/77 [00:00<00:00, 163.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.1647, Val Loss: 0.1970, Val F1: 0.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 77/77 [00:00<00:00, 164.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.1530, Val Loss: 0.2019, Val F1: 0.9309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 77/77 [00:00<00:00, 164.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.1538, Val Loss: 0.2083, Val F1: 0.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 77/77 [00:00<00:00, 164.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.1529, Val Loss: 0.2118, Val F1: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 77/77 [00:00<00:00, 165.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.1487, Val Loss: 0.2127, Val F1: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 77/77 [00:00<00:00, 163.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.1437, Val Loss: 0.2173, Val F1: 0.9253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 77/77 [00:00<00:00, 166.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.1427, Val Loss: 0.2050, Val F1: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 77/77 [00:00<00:00, 157.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.1400, Val Loss: 0.2294, Val F1: 0.9228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 77/77 [00:00<00:00, 160.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.1374, Val Loss: 0.2476, Val F1: 0.9166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 77/77 [00:00<00:00, 164.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.1401, Val Loss: 0.2180, Val F1: 0.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 77/77 [00:00<00:00, 160.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.1379, Val Loss: 0.2289, Val F1: 0.9284\n",
      "Chunk-level evaluation:\n",
      "  Precision: 0.6122\n",
      "  Recall:    0.5676\n",
      "  F1 Score:  0.5891\n",
      "\n",
      "Tag-level evaluation:\n",
      "  Precision: 0.9395\n",
      "  Recall:    0.9395\n",
      "  F1 Score:  0.9395\n",
      "RNN_FastText validation results:\n",
      "  Chunk-level -> Precision: 0.6122, Recall: 0.5676, F1: 0.5891\n",
      "  Tag-level   -> Precision: 0.9395, Recall: 0.9395, F1: 0.9395\n",
      "\n",
      "Training GRU_GloVe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 77/77 [00:00<00:00, 154.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.3430, Val Loss: 0.2188, Val F1: 0.9240\n",
      "Model saved to models/GRU_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 77/77 [00:00<00:00, 152.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.2255, Val Loss: 0.1908, Val F1: 0.9260\n",
      "Model saved to models/GRU_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 77/77 [00:00<00:00, 157.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.2018, Val Loss: 0.1776, Val F1: 0.9311\n",
      "Model saved to models/GRU_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 77/77 [00:00<00:00, 163.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.1899, Val Loss: 0.1834, Val F1: 0.9322\n",
      "Model saved to models/GRU_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 77/77 [00:00<00:00, 161.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.1744, Val Loss: 0.1655, Val F1: 0.9394\n",
      "Model saved to models/GRU_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 77/77 [00:00<00:00, 162.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.1583, Val Loss: 0.1633, Val F1: 0.9409\n",
      "Model saved to models/GRU_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 77/77 [00:00<00:00, 162.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.1506, Val Loss: 0.1710, Val F1: 0.9390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 77/77 [00:00<00:00, 161.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.1368, Val Loss: 0.1634, Val F1: 0.9420\n",
      "Model saved to models/GRU_GloVe_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 77/77 [00:00<00:00, 161.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.1192, Val Loss: 0.1661, Val F1: 0.9402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 77/77 [00:00<00:00, 163.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.1081, Val Loss: 0.1905, Val F1: 0.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 77/77 [00:00<00:00, 163.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.0965, Val Loss: 0.1736, Val F1: 0.9393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 77/77 [00:00<00:00, 162.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.0867, Val Loss: 0.1855, Val F1: 0.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 77/77 [00:00<00:00, 159.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.0733, Val Loss: 0.1902, Val F1: 0.9364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 77/77 [00:00<00:00, 155.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.0605, Val Loss: 0.2314, Val F1: 0.9317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 77/77 [00:00<00:00, 163.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.0532, Val Loss: 0.2434, Val F1: 0.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 77/77 [00:00<00:00, 157.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.0455, Val Loss: 0.2260, Val F1: 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 77/77 [00:00<00:00, 156.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.0403, Val Loss: 0.2401, Val F1: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 77/77 [00:00<00:00, 158.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.0320, Val Loss: 0.2641, Val F1: 0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 77/77 [00:00<00:00, 152.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.0247, Val Loss: 0.2828, Val F1: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 77/77 [00:00<00:00, 154.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.0218, Val Loss: 0.2993, Val F1: 0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 77/77 [00:00<00:00, 158.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.0197, Val Loss: 0.3289, Val F1: 0.9343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 77/77 [00:00<00:00, 162.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.0167, Val Loss: 0.3211, Val F1: 0.9310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 77/77 [00:00<00:00, 157.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.0166, Val Loss: 0.3350, Val F1: 0.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 77/77 [00:00<00:00, 163.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.0167, Val Loss: 0.3039, Val F1: 0.9331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 77/77 [00:00<00:00, 163.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.0138, Val Loss: 0.3279, Val F1: 0.9263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 77/77 [00:00<00:00, 163.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.0146, Val Loss: 0.3298, Val F1: 0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 77/77 [00:00<00:00, 153.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.0130, Val Loss: 0.3383, Val F1: 0.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 77/77 [00:00<00:00, 162.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.0094, Val Loss: 0.3341, Val F1: 0.9350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 77/77 [00:00<00:00, 151.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.0079, Val Loss: 0.3645, Val F1: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 77/77 [00:00<00:00, 157.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.0067, Val Loss: 0.3824, Val F1: 0.9288\n",
      "Chunk-level evaluation:\n",
      "  Precision: 0.6277\n",
      "  Recall:    0.6243\n",
      "  F1 Score:  0.6260\n",
      "\n",
      "Tag-level evaluation:\n",
      "  Precision: 0.9450\n",
      "  Recall:    0.9450\n",
      "  F1 Score:  0.9450\n",
      "GRU_GloVe validation results:\n",
      "  Chunk-level -> Precision: 0.6277, Recall: 0.6243, F1: 0.6260\n",
      "  Tag-level   -> Precision: 0.9450, Recall: 0.9450, F1: 0.9450\n",
      "\n",
      "Training GRU_FastText...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 77/77 [00:00<00:00, 153.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.4794, Val Loss: 0.2636, Val F1: 0.8999\n",
      "Model saved to models/GRU_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 77/77 [00:00<00:00, 161.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.2652, Val Loss: 0.2138, Val F1: 0.9252\n",
      "Model saved to models/GRU_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 77/77 [00:00<00:00, 161.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.2297, Val Loss: 0.1944, Val F1: 0.9313\n",
      "Model saved to models/GRU_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 77/77 [00:00<00:00, 162.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.2164, Val Loss: 0.1972, Val F1: 0.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 77/77 [00:00<00:00, 158.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.2061, Val Loss: 0.1806, Val F1: 0.9357\n",
      "Model saved to models/GRU_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 77/77 [00:00<00:00, 159.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.1953, Val Loss: 0.1792, Val F1: 0.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 77/77 [00:00<00:00, 160.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.1873, Val Loss: 0.1757, Val F1: 0.9375\n",
      "Model saved to models/GRU_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 77/77 [00:00<00:00, 149.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.1834, Val Loss: 0.1750, Val F1: 0.9374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 77/77 [00:00<00:00, 148.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.1747, Val Loss: 0.1734, Val F1: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 77/77 [00:00<00:00, 162.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.1672, Val Loss: 0.1712, Val F1: 0.9399\n",
      "Model saved to models/GRU_FastText_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 77/77 [00:00<00:00, 162.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.1665, Val Loss: 0.1703, Val F1: 0.9391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 77/77 [00:00<00:00, 154.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.1561, Val Loss: 0.1690, Val F1: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 77/77 [00:00<00:00, 161.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.1514, Val Loss: 0.1774, Val F1: 0.9370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 77/77 [00:00<00:00, 163.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.1472, Val Loss: 0.1705, Val F1: 0.9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 77/77 [00:00<00:00, 162.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.1407, Val Loss: 0.1829, Val F1: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 77/77 [00:00<00:00, 163.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.1378, Val Loss: 0.1745, Val F1: 0.9367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 77/77 [00:00<00:00, 162.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.1331, Val Loss: 0.1744, Val F1: 0.9367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 77/77 [00:00<00:00, 160.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.1287, Val Loss: 0.1762, Val F1: 0.9392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 77/77 [00:00<00:00, 161.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.1214, Val Loss: 0.1725, Val F1: 0.9374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 77/77 [00:00<00:00, 162.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.1167, Val Loss: 0.1729, Val F1: 0.9390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 77/77 [00:00<00:00, 161.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.1129, Val Loss: 0.1872, Val F1: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 77/77 [00:00<00:00, 162.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.1069, Val Loss: 0.1918, Val F1: 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 77/77 [00:00<00:00, 162.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.1063, Val Loss: 0.1910, Val F1: 0.9358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 77/77 [00:00<00:00, 163.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.1030, Val Loss: 0.2004, Val F1: 0.9283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 77/77 [00:00<00:00, 143.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.0951, Val Loss: 0.2053, Val F1: 0.9337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 77/77 [00:00<00:00, 142.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.0847, Val Loss: 0.2026, Val F1: 0.9338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 77/77 [00:00<00:00, 131.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.0805, Val Loss: 0.2129, Val F1: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 77/77 [00:00<00:00, 160.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.0723, Val Loss: 0.2271, Val F1: 0.9352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 77/77 [00:00<00:00, 161.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.0694, Val Loss: 0.2287, Val F1: 0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 77/77 [00:00<00:00, 157.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.0692, Val Loss: 0.2372, Val F1: 0.9312\n",
      "Chunk-level evaluation:\n",
      "  Precision: 0.6606\n",
      "  Recall:    0.5838\n",
      "  F1 Score:  0.6198\n",
      "\n",
      "Tag-level evaluation:\n",
      "  Precision: 0.9448\n",
      "  Recall:    0.9448\n",
      "  F1 Score:  0.9448\n",
      "GRU_FastText validation results:\n",
      "  Chunk-level -> Precision: 0.6606, Recall: 0.5838, F1: 0.6198\n",
      "  Tag-level   -> Precision: 0.9448, Recall: 0.9448, F1: 0.9448\n",
      "\n",
      "Results Summary:\n",
      "RNN_GloVe: Chunk F1 = 0.5978, Tag F1 = 0.9386\n",
      "RNN_FastText: Chunk F1 = 0.5891, Tag F1 = 0.9395\n",
      "GRU_GloVe: Chunk F1 = 0.6260, Tag F1 = 0.9450\n",
      "GRU_FastText: Chunk F1 = 0.6198, Tag F1 = 0.9448\n",
      "\n",
      "Best model: GRU_GloVe with Chunk F1 = 0.6260 and Tag F1 = 0.9450\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create directory for plots\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    \n",
    "    # Run main function\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with best model: GRU_GloVe\n",
      "Using embedding model: glove-wiki-gigaword-300\n",
      "Model type: GRU\n",
      "Loading glove-wiki-gigaword-300 embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove-wiki-gigaword-300 loaded\n",
      "Chunk-level evaluation:\n",
      "  Precision: 0.6277\n",
      "  Recall:    0.6243\n",
      "  F1 Score:  0.6260\n",
      "\n",
      "Tag-level evaluation:\n",
      "  Precision: 0.9450\n",
      "  Recall:    0.9450\n",
      "  F1 Score:  0.9450\n",
      "Test Results:\n",
      "Chunk-level:\n",
      "  Precision: 0.6277\n",
      "  Recall:    0.6243\n",
      "  F1 Score:  0.6260\n",
      "Tag-level:\n",
      "  Precision: 0.9450\n",
      "  Recall:    0.9450\n",
      "  F1 Score:  0.9450\n"
     ]
    }
   ],
   "source": [
    "# # Example usage of test function:\n",
    "chunk_metrics, tag_metrics = test_with_best_model('val.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
